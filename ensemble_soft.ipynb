{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import cuda\n",
    "from torchvision import models\n",
    "import albumentations as A\n",
    "from modules.model import create_model\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from argparse import ArgumentParser\n",
    "\n",
    "from dataloader import CustomDataLoader, do_transform, collate_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if cuda.is_available() else 'cpu'\n",
    "num_workers = 4\n",
    "batch_size = 8\n",
    "resize = 256\n",
    "\n",
    "save_dir = '/opt/ml/soft_ensemble'\n",
    "data_dir = '/opt/ml/input/data'\n",
    "model_paths = ['/opt/ml/trained_models/Final_fold_0/ep89_0.7374.pt', '/opt/ml/trained_models/Final_fold_0/ep113_0.7191.pt', '/opt/ml/trained_models/Final_fold_0/ep130_0.7177.pt']\n",
    "use_models = ['mvtb4_unet', 'mvtb4_unet', 'mvtb4_unet']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_with_maps(model_paths, use_models, batch_size=batch_size, num_workers=num_workers, resize=resize, device=device, data_dir=data_dir, save_dir=save_dir):\n",
    "    # load models\n",
    "    models = []\n",
    "    for model_path, use_model in zip(model_paths, use_models):\n",
    "        model = create_model(use_model)\n",
    "        checkpoint = torch.load(model_path, map_location=device)\n",
    "        state_dict = checkpoint.state_dict()\n",
    "        model.load_state_dict(state_dict)\n",
    "        model = model.to(device)\n",
    "        model.eval()\n",
    "        models.append(model)\n",
    "\n",
    "    # data loader\n",
    "    test_dataset = CustomDataLoader(data_dir=os.path.join(data_dir, 'test.json'),\n",
    "                                   mode='test',\n",
    "                                   transform=do_transform(mode='test'),\n",
    "                                   data_path=data_dir)\n",
    "    test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
    "                                                batch_size=batch_size,\n",
    "                                                num_workers=num_workers,\n",
    "                                                collate_fn=collate_fn)\n",
    "    size = resize\n",
    "    transform = A.Compose([A.Resize(size, size)])\n",
    "    print('\\nStart prediction.')\n",
    "    \n",
    "    # Predict\n",
    "    \n",
    "    file_name_list = []\n",
    "    preds_array = np.empty((0, size*size), dtype=np.long)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for step, (imgs, image_infos) in enumerate(tqdm(test_loader)):\n",
    "            # inference (512 x 512)\n",
    "            outs = []\n",
    "            for model in models:\n",
    "                outs.append(model(torch.stack(imgs).to(device)))     # model(torch.stack(imgs).to(device)): torch.Size([N_batch, 11, 512, 512])\n",
    "            outs = torch.stack(outs)\n",
    "            outs = torch.mean(outs, axis=0)\n",
    "            oms = torch.argmax(outs.squeeze(), dim=1).detach().cpu().numpy()\n",
    "            \n",
    "            # resize (256 x 256)\n",
    "            temp_mask = []\n",
    "            for img, mask in zip(np.stack(imgs), oms):\n",
    "                transformed = transform(image=img, mask=mask)\n",
    "                mask = transformed['mask']\n",
    "                temp_mask.append(mask)\n",
    "                \n",
    "            oms = np.array(temp_mask)\n",
    "            \n",
    "            oms = oms.reshape([oms.shape[0], size*size]).astype(int)\n",
    "            preds_array = np.vstack((preds_array, oms))\n",
    "            \n",
    "            file_name_list.append([i['file_name'] for i in image_infos])\n",
    "\n",
    "    print(\"End prediction.\")\n",
    "    file_names = [y for x in file_name_list for y in x]\n",
    "    \n",
    "    print(\"Start Inference\")\n",
    "    # sample_submisson.csv 열기\n",
    "    submission = pd.read_csv('/opt/ml/input/code/submission/sample_submission.csv', index_col=None)\n",
    "\n",
    "    # PredictionString 대입\n",
    "    for file_name, string in zip(file_names, preds_array):\n",
    "        submission = submission.append({\"image_id\" : file_name, \"PredictionString\" : ' '.join(str(e) for e in string.tolist())}, \n",
    "                                    ignore_index=True)\n",
    "\n",
    "    # submission.csv로 저장\n",
    "    submission.to_csv(os.path.join(save_dir, 'submission.csv'), index=False)\n",
    "    print(\"End Inference\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/103 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "\n",
      "Start prediction.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 103/103 [08:39<00:00,  5.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End prediction.\n",
      "Start Inference\n",
      "End Inference\n"
     ]
    }
   ],
   "source": [
    "test_with_maps(model_paths, use_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5 (default, Sep  4 2020, 07:30:14) \n[GCC 7.3.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

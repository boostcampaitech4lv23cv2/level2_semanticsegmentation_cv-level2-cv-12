{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import cuda\n",
    "from torchvision import models\n",
    "import albumentations as A\n",
    "from modules.model import create_model\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from argparse import ArgumentParser\n",
    "\n",
    "from dataloader import CustomDataLoader, do_transform, collate_fn\n",
    "from utils.utils import label_accuracy_score, add_hist, set_seed\n",
    "from modules.losses import create_criterion\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if cuda.is_available() else 'cpu'\n",
    "num_workers = 4\n",
    "batch_size = 8\n",
    "resize = 256\n",
    "\n",
    "val_json_path = '/opt/ml/input/data/seed21/val_0.json'\n",
    "data_dir = '/opt/ml/input/data'\n",
    "model_dir = '/opt/ml/trained_models/Final_fold_0'   # = save_dir\n",
    "use_model = 'mvtb4_unet'\n",
    "use_loss = 'combo'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation(model, data_loader, criterion, device):\n",
    "    model.eval()\n",
    "    category_names = ['Background', 'General trash', 'Paper', 'Paper pack', 'Metal', 'Glass', 'Plastic', 'Styrofoam', 'Plastic bag', 'Battery', 'Clothing']\n",
    "\n",
    "    with torch.no_grad():\n",
    "        n_class = 11\n",
    "        total_loss = 0\n",
    "        cnt = 0\n",
    "        hist = np.zeros((n_class, n_class))\n",
    "\n",
    "        for step, (images, masks, image_infos) in enumerate(tqdm(data_loader)):\n",
    "            images = torch.stack(images)       \n",
    "            masks = torch.stack(masks).long()\n",
    "            images, masks = images.to(device), masks.to(device)            \n",
    "            \n",
    "            # device 할당\n",
    "            model = model.to(device)\n",
    "            \n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, masks)\n",
    "            total_loss += loss\n",
    "            cnt += 1\n",
    "            outputs = torch.argmax(outputs, dim=1).detach().cpu().numpy()\n",
    "            masks = masks.detach().cpu().numpy()\n",
    "\n",
    "            hist = add_hist(hist, masks, outputs, n_class=n_class)\n",
    "\n",
    "        acc, acc_cls, mIoU, fwavacc, IoU = label_accuracy_score(hist)\n",
    "        IoU_by_class = [{classes : round(IoU,4)} for IoU, classes in zip(IoU , category_names)]\n",
    "        avrg_loss = total_loss / cnt\n",
    "        print(f'Validation. Average Loss: {round(avrg_loss.item(), 4)}, Accuracy : {round(acc, 4)}, mIoU: {round(mIoU, 4)}')\n",
    "        print(f'IoU by class : {IoU_by_class}')\n",
    "        \n",
    "    return avrg_loss, mIoU, IoU_by_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def greedy_soup(model_file_names, use_model=use_model, use_loss=use_loss, \n",
    "                data_dir=data_dir, model_dir=model_dir, val_json_path=val_json_path,\n",
    "                device=device, num_workers=num_workers, batch_size=batch_size, resize=resize):\n",
    "    # data loader\n",
    "    val_dataset = CustomDataLoader(data_dir=val_json_path,\n",
    "                                   mode='val',\n",
    "                                   transform=do_transform(mode='val'),\n",
    "                                   data_path=data_dir)                                   \n",
    "    val_loader = torch.utils.data.DataLoader(dataset=val_dataset,\n",
    "                                             batch_size=batch_size,\n",
    "                                             shuffle=False,\n",
    "                                             num_workers=num_workers,\n",
    "                                             collate_fn=collate_fn)\n",
    "\n",
    "    n_class = 11\n",
    "    criterion = create_criterion(use_loss)\n",
    "    FLAG_First = True\n",
    "    stacked_files = []\n",
    "\n",
    "    # load models\n",
    "    for model_file_name in model_file_names:\n",
    "        print(model_file_name)\n",
    "        model = create_model(use_model)\n",
    "        checkpoint = torch.load(os.path.join(model_dir, model_file_name), map_location=device)\n",
    "        state_dict = checkpoint.state_dict()\n",
    "        model.load_state_dict(state_dict)\n",
    "        model = model.to(device)\n",
    "\n",
    "        if FLAG_First:\n",
    "            model_soup = model\n",
    "            #avrg_loss_soup, mIoU_soup, IoU_by_class_soup = validation(model, val_loader, criterion, device)\n",
    "            FLAG_First = False\n",
    "            stacked_files.append(model_file_name)\n",
    "            continue\n",
    "        \n",
    "        else:\n",
    "            beta = len(stacked_files)/(len(stacked_files) + 1)\n",
    "            params_soup = model_soup.named_parameters()\n",
    "            params_temp = model.named_parameters()\n",
    "\n",
    "            dict_params_temp = dict(params_temp)\n",
    "            print(beta)\n",
    "            print(dict_params_temp['model.encoder.patch_embed1.proj.weight'][0, 0, 0])\n",
    "            for name_soup, param_soup in params_soup:\n",
    "                print(param_soup.data)\n",
    "                if name_soup in dict_params_temp:\n",
    "                    dict_params_temp[name_soup].data.copy_(beta*param_soup.data + (1-beta)*dict_params_temp[name_soup].data)\n",
    "                else: assert False, 'No param named ' + name_soup\n",
    "            print(dict_params_temp['model.encoder.patch_embed1.proj.weight'][0, 0, 0])\n",
    "            #model_soup_temp = \n",
    "            \n",
    "        assert False\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ep89_0.7374.pt', 'ep88_0.7366.pt', 'ep87_0.7363.pt', 'ep90_0.7363.pt', 'ep84_0.7352.pt', 'ep86_0.7329.pt', 'ep85_0.7327.pt', 'ep79_0.7306.pt', 'ep81_0.7242.pt', 'ep77_0.7232.pt', 'ep113_0.7191.pt', 'ep114_0.7181.pt', 'ep130_0.7177.pt', 'ep118_0.7175.pt', 'ep83_0.7174.pt']\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m file_list\u001b[39m.\u001b[39msort(key\u001b[39m=\u001b[39m\u001b[39mlambda\u001b[39;00m x: \u001b[39mfloat\u001b[39m(x[\u001b[39m-\u001b[39m\u001b[39m9\u001b[39m:\u001b[39m-\u001b[39m\u001b[39m3\u001b[39m]), reverse\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m      4\u001b[0m \u001b[39mprint\u001b[39m(file_list)\n\u001b[0;32m----> 5\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m      6\u001b[0m greedy_soup(file_list)\n\u001b[1;32m      8\u001b[0m \u001b[39m#test_with_maps(model_paths, use_models)\u001b[39;00m\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# sort models (use only topK-saved dir)\n",
    "file_list = [f for f in os.listdir(model_dir) if f.endswith('.pt')]\n",
    "file_list.sort(key=lambda x: float(x[-9:-3]), reverse=True)\n",
    "print(file_list)\n",
    "assert False\n",
    "greedy_soup(file_list)\n",
    "\n",
    "#test_with_maps(model_paths, use_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "    size = resize\n",
    "    transform = A.Compose([A.Resize(size, size)])\n",
    "    print('\\nStart prediction.')\n",
    "    \n",
    "    # Predict\n",
    "    file_name_list = []\n",
    "    preds_array = np.empty((0, size*size), dtype=np.long)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        hist = np.zeros((n_class, n_class))\n",
    "        for step, (imgs, masks, image_infos) in enumerate(tqdm(val_loader)):\n",
    "            # inference (512 x 512)\n",
    "            outs = []\n",
    "            for model in models:\n",
    "                outs.append(model(torch.stack(imgs).to(device)))     # model(torch.stack(imgs).to(device)): torch.Size([N_batch, 11, 512, 512])\n",
    "            outs = torch.stack(outs)\n",
    "            \n",
    "            \n",
    "            \n",
    "            outs = torch.mean(outs, axis=0)\n",
    "            oms = torch.argmax(outs.squeeze(), dim=1).detach().cpu().numpy()\n",
    "            \n",
    "            # resize (256 x 256)\n",
    "            temp_mask = []\n",
    "            for img, mask in zip(np.stack(imgs), oms):\n",
    "                transformed = transform(image=img, mask=mask)\n",
    "                mask = transformed['mask']\n",
    "                temp_mask.append(mask)\n",
    "                \n",
    "            oms = np.array(temp_mask)\n",
    "            \n",
    "            oms = oms.reshape([oms.shape[0], size*size]).astype(int)\n",
    "            preds_array = np.vstack((preds_array, oms))\n",
    "            \n",
    "            file_name_list.append([i['file_name'] for i in image_infos])\n",
    "\n",
    "    print(\"End prediction.\")\n",
    "    file_names = [y for x in file_name_list for y in x]\n",
    "    \n",
    "    print(\"Start Inference\")\n",
    "    # sample_submisson.csv 열기\n",
    "    submission = pd.read_csv('/opt/ml/input/code/submission/sample_submission.csv', index_col=None)\n",
    "\n",
    "    # PredictionString 대입\n",
    "    for file_name, string in zip(file_names, preds_array):\n",
    "        submission = submission.append({\"image_id\" : file_name, \"PredictionString\" : ' '.join(str(e) for e in string.tolist())}, \n",
    "                                    ignore_index=True)\n",
    "\n",
    "    # submission.csv로 저장\n",
    "    submission.to_csv(os.path.join(save_dir, 'submission.csv'), index=False)\n",
    "    print(\"End Inference\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5 (default, Sep  4 2020, 07:30:14) \n[GCC 7.3.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
